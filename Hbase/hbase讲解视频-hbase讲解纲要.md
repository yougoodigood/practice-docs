# hbase讲解纲要

## 1.hbase概况

文档1

## 2.hbase的操作，先演示下hbase的操作，代码和命令行

shell操作：

文档2   

java代码操作：
get
scan
put
delete

批量操作：

bulkLoad

批量get，线程池

scala代码操作：...

## 3.hbase的设计要点

文档3

性能测试：

elastic-search+hbase 性能测试，官网上有




## 4.hbase存取要点

几个误区：

**误区1**：实时查询和批查询搞混淆了

**误区2**：以为数据能存进去，能快速拿出来就完事了！但是，这仅仅是处理性能方面，上下文数据，中间数据，数据丢失 等情况没有考虑
**误区3**：hadoop，spark 计算能力比较强，因为多节点；不是计算能力很变态
**误区4**：spark-streaming实时计算，是指把实时数据先收集成一小批一小批，再处理这一小批的数据。



如果是我设计hbase数据存取，我会怎么考虑？

（1）磁盘io，网络io，cpu io，内存io，瓶颈在最差的那个

（2）使用场景

#### 存数据

存数据，存原始报文的hdfs 是否跟的上kafka？资源竞争，影响怎么办？
存数据时，hbase不是一条条存的，要做成批量存的
存数据，hbase是否跟的上kafka？资源竞争

可测



#### 取数据-全量数据

get 某个列
get 单条数据
batch get 分页
batch get 2万-3万条
几万条数据是否拿出来就能用？
能，超过10万，http撑不住；jvm撑不住。client是单机的，client在外网环境更严重


不能，不仅是几万条不能直接用，如果一个月的数据不能直接用？

总数据如下：
20*365=15T
272G/24/60/60=0.00315G=3.15M/s
20.7*10000*10000/24/60/60=24000条/s
乘以一个月：
24000*60*60*24*30=62,208,000,000
不可能

62,208,000,000条，统计：计数，累加，平均，百分比。
不可能







#### 取数据-增量业务数据

一个rowkey，原，10个参数，现，要加1个参数
2种：
1.从当前时间开始添加  
能

2.从原始报文库中找出这个参数，将hbase中已有的数据都加上这个参数
极有可能批任务几个星期以上







##### 忌1：batch get 数据上限不超过10万。

##### 忌2：不能实时计算、统计上千万，上亿条数据。



#### 取数据-批查询



**如果不能实时计算、统计hbase中上千万条的数据，那么在哪里解决这个问题？**



![微信图片_20190306195553](D:\BIG-DATA-资料\hbase演示材料\微信图片_20190306195553.png)

思路：

1.在存hbase前计数，累加，平均，百分比，行不行？

2.存进hbase之后，批任务累加，平均，百分比，行不行？

对于需求条件固定，已知，两种都可以。思路1稍好。



问题：

前端需求条件有变化？

比如原来结果A = （参数1，参数2）的过去一个月的统计结果，相关的业务参数和业务结果在存hbase前就统计好

现在新需求：结果B=（参数3，参数4）的过去一个月的统计结果，因为之前没有这个需求，所以相关的业务参数和业务结果在hbase中不存在



这个问题，就必须得全表批查询，统计

数据量：62,208,000,000条/月



思路1：不要用client去get，直接在集群上算；spark+hbase+es

思路2：数据的颗粒度，直到 单列，而不是单条

可测，必须要先测



#### 取数据-上下文数据

1.把序号写进rowkey中

2.把序号写进列中